{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import pickle\n",
    "\n",
    "import octis\n",
    "from octis.optimization.optimizer import Optimizer\n",
    "from skopt.space.space import Real, Categorical, Integer\n",
    "from octis.models.NeuralLDA import NeuralLDA\n",
    "from octis.dataset.dataset import Dataset\n",
    "from octis.evaluation_metrics.diversity_metrics import TopicDiversity\n",
    "from octis.evaluation_metrics.coherence_metrics import Coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class NeuralLDA(AVITM):\n",
      "    def __init__(\n",
      "        self, num_topics=10, activation='softplus', dropout=0.2,\n",
      "        learn_priors=True, batch_size=64, lr=2e-3, momentum=0.99,\n",
      "        solver='adam', num_epochs=100, reduce_on_plateau=False, prior_mean=0.0,\n",
      "        prior_variance=None, num_layers=2, num_neurons=100, num_samples=10,\n",
      "            use_partitions=True):\n",
      "        super().__init__(\n",
      "            num_topics=num_topics, model_type='LDA', activation=activation,\n",
      "            dropout=dropout, learn_priors=learn_priors, batch_size=batch_size,\n",
      "            lr=lr, momentum=momentum, solver=solver, num_epochs=num_epochs,\n",
      "            reduce_on_plateau=reduce_on_plateau, prior_mean=prior_mean,\n",
      "            prior_variance=prior_variance, num_layers=num_layers,\n",
      "            num_neurons=num_neurons, num_samples=num_samples,\n",
      "            use_partitions=use_partitions)\n",
      "\n",
      "    def train_model(self, dataset, hyperparameters=None, top_words=10):\n",
      "        return super().train_model(\n",
      "            dataset=dataset, hyperparameters=hyperparameters,\n",
      "            top_words=top_words)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "print(inspect.getsource(octis.models.NeuralLDA.NeuralLDA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset()\n",
    "dataset.load_custom_dataset_from_folder(\"content/corpus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = Coherence(texts=dataset.get_corpus(), measure='c_v')\n",
    "umass = Coherence(texts=dataset.get_corpus(), measure='u_mass')\n",
    "uci = Coherence(texts=dataset.get_corpus(), measure='c_uci')\n",
    "npmi = Coherence(texts=dataset.get_corpus())\n",
    "topic_diversity = TopicDiversity(topk=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Model\n",
    "model = NeuralLDA(num_topics=7,use_partitions=False,num_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/50]\tSamples: [15000/750000]\tTrain Loss: 284.3912905598958\tTime: 0:00:09.729613\n",
      "Epoch: [2/50]\tSamples: [30000/750000]\tTrain Loss: 272.96326803385415\tTime: 0:00:08.712471\n",
      "Epoch: [3/50]\tSamples: [45000/750000]\tTrain Loss: 269.8860184244792\tTime: 0:00:08.070113\n",
      "Epoch: [4/50]\tSamples: [60000/750000]\tTrain Loss: 269.4373930013021\tTime: 0:00:08.595411\n",
      "Epoch: [5/50]\tSamples: [75000/750000]\tTrain Loss: 268.38486487630206\tTime: 0:00:10.598162\n",
      "Epoch: [6/50]\tSamples: [90000/750000]\tTrain Loss: 268.0924031575521\tTime: 0:00:10.385163\n",
      "Epoch: [7/50]\tSamples: [105000/750000]\tTrain Loss: 267.91443076171873\tTime: 0:00:10.513545\n",
      "Epoch: [8/50]\tSamples: [120000/750000]\tTrain Loss: 268.3832941080729\tTime: 0:00:10.267352\n",
      "Epoch: [9/50]\tSamples: [135000/750000]\tTrain Loss: 268.33092294921875\tTime: 0:00:07.676441\n",
      "Epoch: [10/50]\tSamples: [150000/750000]\tTrain Loss: 267.95362682291665\tTime: 0:00:07.320500\n",
      "Epoch: [11/50]\tSamples: [165000/750000]\tTrain Loss: 267.9925103190104\tTime: 0:00:07.555464\n",
      "Epoch: [12/50]\tSamples: [180000/750000]\tTrain Loss: 267.8548974934896\tTime: 0:00:07.743114\n",
      "Epoch: [13/50]\tSamples: [195000/750000]\tTrain Loss: 267.63079208984374\tTime: 0:00:07.423038\n",
      "Epoch: [14/50]\tSamples: [210000/750000]\tTrain Loss: 267.84293938802085\tTime: 0:00:07.381195\n",
      "Epoch: [15/50]\tSamples: [225000/750000]\tTrain Loss: 267.8031028645833\tTime: 0:00:07.954915\n",
      "Epoch: [16/50]\tSamples: [240000/750000]\tTrain Loss: 267.6865318359375\tTime: 0:00:07.171567\n",
      "Epoch: [17/50]\tSamples: [255000/750000]\tTrain Loss: 267.54879690755206\tTime: 0:00:06.936007\n",
      "Epoch: [18/50]\tSamples: [270000/750000]\tTrain Loss: 267.60942509765624\tTime: 0:00:07.107510\n",
      "Epoch: [19/50]\tSamples: [285000/750000]\tTrain Loss: 267.578275390625\tTime: 0:00:06.912349\n",
      "Epoch: [20/50]\tSamples: [300000/750000]\tTrain Loss: 267.44029544270836\tTime: 0:00:06.816978\n",
      "Epoch: [21/50]\tSamples: [315000/750000]\tTrain Loss: 267.6195892252604\tTime: 0:00:06.925570\n",
      "Epoch: [22/50]\tSamples: [330000/750000]\tTrain Loss: 267.06260345052084\tTime: 0:00:07.235005\n",
      "Epoch: [23/50]\tSamples: [345000/750000]\tTrain Loss: 267.1774733072917\tTime: 0:00:06.802842\n",
      "Epoch: [24/50]\tSamples: [360000/750000]\tTrain Loss: 267.4144657552083\tTime: 0:00:06.758574\n",
      "Epoch: [25/50]\tSamples: [375000/750000]\tTrain Loss: 266.9518462890625\tTime: 0:00:06.830220\n",
      "Epoch: [26/50]\tSamples: [390000/750000]\tTrain Loss: 267.46545159505206\tTime: 0:00:06.806057\n",
      "Epoch: [27/50]\tSamples: [405000/750000]\tTrain Loss: 267.922637109375\tTime: 0:00:06.668142\n",
      "Epoch: [28/50]\tSamples: [420000/750000]\tTrain Loss: 267.48218359375\tTime: 0:00:06.900530\n",
      "Epoch: [29/50]\tSamples: [435000/750000]\tTrain Loss: 266.99601809895836\tTime: 0:00:06.701120\n",
      "Epoch: [30/50]\tSamples: [450000/750000]\tTrain Loss: 267.52656494140626\tTime: 0:00:06.716606\n",
      "Epoch: [31/50]\tSamples: [465000/750000]\tTrain Loss: 267.117634375\tTime: 0:00:06.763284\n",
      "Epoch: [32/50]\tSamples: [480000/750000]\tTrain Loss: 267.4784810546875\tTime: 0:00:06.690749\n",
      "Epoch: [33/50]\tSamples: [495000/750000]\tTrain Loss: 267.35464658203125\tTime: 0:00:06.739859\n",
      "Epoch: [34/50]\tSamples: [510000/750000]\tTrain Loss: 267.1269336263021\tTime: 0:00:06.964469\n",
      "Epoch: [35/50]\tSamples: [525000/750000]\tTrain Loss: 267.18167454427083\tTime: 0:00:06.741941\n",
      "Epoch: [36/50]\tSamples: [540000/750000]\tTrain Loss: 267.3969728515625\tTime: 0:00:06.623697\n",
      "Epoch: [37/50]\tSamples: [555000/750000]\tTrain Loss: 267.17867607421874\tTime: 0:00:06.731616\n",
      "Epoch: [38/50]\tSamples: [570000/750000]\tTrain Loss: 267.1876805338542\tTime: 0:00:06.616958\n",
      "Epoch: [39/50]\tSamples: [585000/750000]\tTrain Loss: 267.246262890625\tTime: 0:00:06.748805\n",
      "Epoch: [40/50]\tSamples: [600000/750000]\tTrain Loss: 267.544919921875\tTime: 0:00:06.872777\n",
      "Epoch: [41/50]\tSamples: [615000/750000]\tTrain Loss: 267.28805244140625\tTime: 0:00:06.840614\n",
      "Epoch: [42/50]\tSamples: [630000/750000]\tTrain Loss: 266.9871282226562\tTime: 0:00:06.712250\n",
      "Epoch: [43/50]\tSamples: [645000/750000]\tTrain Loss: 267.34244296875\tTime: 0:00:07.004206\n",
      "Epoch: [44/50]\tSamples: [660000/750000]\tTrain Loss: 266.80219248046876\tTime: 0:00:06.750450\n",
      "Epoch: [45/50]\tSamples: [675000/750000]\tTrain Loss: 267.05454674479165\tTime: 0:00:06.959396\n",
      "Epoch: [46/50]\tSamples: [690000/750000]\tTrain Loss: 267.6686989908854\tTime: 0:00:06.809643\n",
      "Epoch: [47/50]\tSamples: [705000/750000]\tTrain Loss: 267.6687634114583\tTime: 0:00:06.879389\n",
      "Epoch: [48/50]\tSamples: [720000/750000]\tTrain Loss: 267.29270970052085\tTime: 0:00:06.744066\n",
      "Epoch: [49/50]\tSamples: [735000/750000]\tTrain Loss: 267.130309765625\tTime: 0:00:06.828630\n",
      "Epoch: [50/50]\tSamples: [750000/750000]\tTrain Loss: 267.1106242838542\tTime: 0:00:06.940834\n"
     ]
    }
   ],
   "source": [
    "# Train the model using default partitioning choice \n",
    "output = model.train_model(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "progress idk recommendation tho library stuck jump avatar pick wanna\n",
      "mind bore glitchy repeat begin dislike gets anyway appreciate robux\n",
      "perfect learn min forward coin highly episode middle awesome cast\n",
      "disconnect computer album artist reopen happy choice tok trouble shut\n",
      "telegram card receive customer support number link file cash group\n",
      "game play good app like use fix video really time\n",
      "offline exit barely laptop caption easily accidentally four hold bluetooth\n"
     ]
    }
   ],
   "source": [
    "for t in output['topics']:\n",
    "  print(\" \".join(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic diversity: 1.0\n",
      "coherence CV: 0.3314369671187864\n",
      "coherence NPMI: -0.18592447144901714\n",
      "coherence UCI: -5.799499560821853\n"
     ]
    }
   ],
   "source": [
    "topic_diversity_score = topic_diversity.score(output)\n",
    "cv_score = cv.score(output)\n",
    "npmi_score = npmi.score(output)\n",
    "uci_score = uci.score(output)\n",
    "\n",
    "print(f\"topic diversity: {topic_diversity_score}\")\n",
    "print(f\"coherence CV: {cv_score}\")\n",
    "print(f\"coherence NPMI: {npmi_score}\")\n",
    "print(f\"coherence UCI: {uci_score}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
