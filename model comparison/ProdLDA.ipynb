{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import pickle\n",
    "\n",
    "import octis\n",
    "from octis.optimization.optimizer import Optimizer\n",
    "from skopt.space.space import Real, Categorical, Integer\n",
    "from octis.models.ProdLDA import ProdLDA\n",
    "from octis.dataset.dataset import Dataset\n",
    "from octis.evaluation_metrics.diversity_metrics import TopicDiversity\n",
    "from octis.evaluation_metrics.coherence_metrics import Coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class ProdLDA(AVITM):\n",
      "    def __init__(\n",
      "        self, num_topics=10, activation='softplus', dropout=0.2,\n",
      "        learn_priors=True, batch_size=64, lr=2e-3, momentum=0.99,\n",
      "        solver='adam', num_epochs=100, reduce_on_plateau=False, prior_mean=0.0,\n",
      "        prior_variance=None, num_layers=2, num_neurons=100, num_samples=10,\n",
      "            use_partitions=True):\n",
      "        super().__init__(\n",
      "            num_topics=num_topics, model_type='prodLDA', activation=activation,\n",
      "            dropout=dropout, learn_priors=learn_priors, batch_size=batch_size,\n",
      "            lr=lr, momentum=momentum, solver=solver, num_epochs=num_epochs,\n",
      "            reduce_on_plateau=reduce_on_plateau, prior_mean=prior_mean,\n",
      "            prior_variance=prior_variance, num_layers=num_layers,\n",
      "            num_neurons=num_neurons, num_samples=num_samples,\n",
      "            use_partitions=use_partitions)\n",
      "\n",
      "    def train_model(self, dataset, hyperparameters=None, top_words=10):\n",
      "        return super().train_model(dataset, hyperparameters, top_words)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "print(inspect.getsource(octis.models.ProdLDA.ProdLDA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset()\n",
    "dataset.load_custom_dataset_from_folder(\"content/corpus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = Coherence(texts=dataset.get_corpus(), measure='c_v')\n",
    "umass = Coherence(texts=dataset.get_corpus(), measure='u_mass')\n",
    "uci = Coherence(texts=dataset.get_corpus(), measure='c_uci')\n",
    "npmi = Coherence(texts=dataset.get_corpus())\n",
    "topic_diversity = TopicDiversity(topk=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Model\n",
    "model = ProdLDA(num_topics=7,num_epochs=50, use_partitions=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/50]\tSamples: [15000/750000]\tTrain Loss: 300.5341977213542\tTime: 0:00:06.151467\n",
      "Epoch: [2/50]\tSamples: [30000/750000]\tTrain Loss: 288.8199872721354\tTime: 0:00:05.721865\n",
      "Epoch: [3/50]\tSamples: [45000/750000]\tTrain Loss: 285.86564563802085\tTime: 0:00:06.161407\n",
      "Epoch: [4/50]\tSamples: [60000/750000]\tTrain Loss: 284.77738372395834\tTime: 0:00:06.114523\n",
      "Epoch: [5/50]\tSamples: [75000/750000]\tTrain Loss: 283.9300390299479\tTime: 0:00:06.216062\n",
      "Epoch: [6/50]\tSamples: [90000/750000]\tTrain Loss: 283.54364661458334\tTime: 0:00:06.944169\n",
      "Epoch: [7/50]\tSamples: [105000/750000]\tTrain Loss: 283.4546566080729\tTime: 0:00:06.554561\n",
      "Epoch: [8/50]\tSamples: [120000/750000]\tTrain Loss: 283.2999038411458\tTime: 0:00:06.774831\n",
      "Epoch: [9/50]\tSamples: [135000/750000]\tTrain Loss: 283.1027125\tTime: 0:00:06.394689\n",
      "Epoch: [10/50]\tSamples: [150000/750000]\tTrain Loss: 282.93064964192706\tTime: 0:00:06.329443\n",
      "Epoch: [11/50]\tSamples: [165000/750000]\tTrain Loss: 282.8739964518229\tTime: 0:00:06.093482\n",
      "Epoch: [12/50]\tSamples: [180000/750000]\tTrain Loss: 282.832555078125\tTime: 0:00:05.813498\n",
      "Epoch: [13/50]\tSamples: [195000/750000]\tTrain Loss: 282.83679973958334\tTime: 0:00:05.957051\n",
      "Epoch: [14/50]\tSamples: [210000/750000]\tTrain Loss: 282.7663358072917\tTime: 0:00:06.031788\n",
      "Epoch: [15/50]\tSamples: [225000/750000]\tTrain Loss: 282.71505693359376\tTime: 0:00:06.777194\n",
      "Epoch: [16/50]\tSamples: [240000/750000]\tTrain Loss: 282.6118855143229\tTime: 0:00:06.773149\n",
      "Epoch: [17/50]\tSamples: [255000/750000]\tTrain Loss: 282.38886725260414\tTime: 0:00:05.985643\n",
      "Epoch: [18/50]\tSamples: [270000/750000]\tTrain Loss: 282.4569130208333\tTime: 0:00:05.926963\n",
      "Epoch: [19/50]\tSamples: [285000/750000]\tTrain Loss: 282.43911647135417\tTime: 0:00:05.802864\n",
      "Epoch: [20/50]\tSamples: [300000/750000]\tTrain Loss: 282.28735602213544\tTime: 0:00:05.756049\n",
      "Epoch: [21/50]\tSamples: [315000/750000]\tTrain Loss: 282.1881035481771\tTime: 0:00:05.690368\n",
      "Epoch: [22/50]\tSamples: [330000/750000]\tTrain Loss: 282.0604865234375\tTime: 0:00:05.801208\n",
      "Epoch: [23/50]\tSamples: [345000/750000]\tTrain Loss: 282.1387341145833\tTime: 0:00:05.730322\n",
      "Epoch: [24/50]\tSamples: [360000/750000]\tTrain Loss: 282.17105911458333\tTime: 0:00:05.776469\n",
      "Epoch: [25/50]\tSamples: [375000/750000]\tTrain Loss: 282.06232412109375\tTime: 0:00:05.776986\n",
      "Epoch: [26/50]\tSamples: [390000/750000]\tTrain Loss: 282.11117805989585\tTime: 0:00:05.702869\n",
      "Epoch: [27/50]\tSamples: [405000/750000]\tTrain Loss: 281.8650571614583\tTime: 0:00:05.630063\n",
      "Epoch: [28/50]\tSamples: [420000/750000]\tTrain Loss: 281.9838944335938\tTime: 0:00:05.794160\n",
      "Epoch: [29/50]\tSamples: [435000/750000]\tTrain Loss: 281.89673645833335\tTime: 0:00:05.737974\n",
      "Epoch: [30/50]\tSamples: [450000/750000]\tTrain Loss: 282.03233655598956\tTime: 0:00:05.784335\n",
      "Epoch: [31/50]\tSamples: [465000/750000]\tTrain Loss: 281.95456962890626\tTime: 0:00:05.720644\n",
      "Epoch: [32/50]\tSamples: [480000/750000]\tTrain Loss: 282.0282544270833\tTime: 0:00:05.928813\n",
      "Epoch: [33/50]\tSamples: [495000/750000]\tTrain Loss: 281.71045029296874\tTime: 0:00:05.739270\n",
      "Epoch: [34/50]\tSamples: [510000/750000]\tTrain Loss: 281.95683079427084\tTime: 0:00:05.792231\n",
      "Epoch: [35/50]\tSamples: [525000/750000]\tTrain Loss: 281.66940400390627\tTime: 0:00:05.598397\n",
      "Epoch: [36/50]\tSamples: [540000/750000]\tTrain Loss: 281.92371910807293\tTime: 0:00:05.529984\n",
      "Epoch: [37/50]\tSamples: [555000/750000]\tTrain Loss: 281.94124427083335\tTime: 0:00:05.794840\n",
      "Epoch: [38/50]\tSamples: [570000/750000]\tTrain Loss: 281.9307057942708\tTime: 0:00:06.152949\n",
      "Epoch: [39/50]\tSamples: [585000/750000]\tTrain Loss: 281.80575696614585\tTime: 0:00:05.929761\n",
      "Epoch: [40/50]\tSamples: [600000/750000]\tTrain Loss: 281.81481591796876\tTime: 0:00:06.106877\n",
      "Epoch: [41/50]\tSamples: [615000/750000]\tTrain Loss: 281.77260817057294\tTime: 0:00:05.961307\n",
      "Epoch: [42/50]\tSamples: [630000/750000]\tTrain Loss: 281.7993326171875\tTime: 0:00:05.814708\n",
      "Epoch: [43/50]\tSamples: [645000/750000]\tTrain Loss: 281.7319592122396\tTime: 0:00:05.712527\n",
      "Epoch: [44/50]\tSamples: [660000/750000]\tTrain Loss: 281.76142096354164\tTime: 0:00:05.614225\n",
      "Epoch: [45/50]\tSamples: [675000/750000]\tTrain Loss: 281.95843684895834\tTime: 0:00:05.745443\n",
      "Epoch: [46/50]\tSamples: [690000/750000]\tTrain Loss: 281.87375426432294\tTime: 0:00:05.700064\n",
      "Epoch: [47/50]\tSamples: [705000/750000]\tTrain Loss: 281.86292044270834\tTime: 0:00:05.992773\n",
      "Epoch: [48/50]\tSamples: [720000/750000]\tTrain Loss: 281.777509375\tTime: 0:00:05.776199\n",
      "Epoch: [49/50]\tSamples: [735000/750000]\tTrain Loss: 281.7722347005208\tTime: 0:00:05.665648\n",
      "Epoch: [50/50]\tSamples: [750000/750000]\tTrain Loss: 281.7081360026042\tTime: 0:00:05.666208\n"
     ]
    }
   ],
   "source": [
    "# Train the model using default partitioning choice \n",
    "output = model.train_model(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "song playlist music spotify ad listen video youtube premium watch\n",
      "chat ai feature snapchat top option see split post remove\n",
      "expecially fave aka whichever norma gives evan wether irreversible crown\n",
      "account money cash support card help email customer never service\n",
      "work open issue reinstall app notification even phone update try\n",
      "expecially fave wether norma aka evan milk whichever crown gives\n",
      "game really roblox fun sometimes love good star thing glitch\n"
     ]
    }
   ],
   "source": [
    "for t in output['topics']:\n",
    "  print(\" \".join(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic diversity: 0.8714285714285714\n",
      "coherence CV: 0.6074554369776356\n",
      "coherence NPMI: -0.014789812363450953\n",
      "coherence UCI: -1.9399664665362988\n"
     ]
    }
   ],
   "source": [
    "topic_diversity_score = topic_diversity.score(output)\n",
    "cv_score = cv.score(output)\n",
    "npmi_score = npmi.score(output)\n",
    "uci_score = uci.score(output)\n",
    "\n",
    "print(f\"topic diversity: {topic_diversity_score}\")\n",
    "print(f\"coherence CV: {cv_score}\")\n",
    "print(f\"coherence NPMI: {npmi_score}\")\n",
    "print(f\"coherence UCI: {uci_score}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
